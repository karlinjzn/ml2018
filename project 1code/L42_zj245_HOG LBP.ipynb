{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline --no-import-all\n",
    "# OpenCV bindings\n",
    "import cv2 as cv\n",
    "# To performing path manipulations \n",
    "import os\n",
    "# Local Binary Pattern function\n",
    "from skimage.feature import local_binary_pattern\n",
    "# To calculate a normalized histogram \n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.preprocessing import normalize\n",
    "# Utility package -- use pip install cvutils to install\n",
    "import cvutils\n",
    "# To read class from file\n",
    "import csv\n",
    "import glob\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "DataPath = '/Users/zhuonijie/Desktop/TrainingImages copy/'\n",
    "\n",
    "# load images\n",
    "def loadImg(fileName,dsize1,dsize2): \n",
    "    '''\n",
    "    load image, resize, rgb2gray, equal histo \n",
    "    :param fileName: file name \n",
    "    :param dsize: same size, tuple \n",
    "    :return: image \n",
    "    '''\n",
    "    img = cv.imread(fileName)\n",
    "    retImg = cv.resize(img,(dsize1,dsize2)) \n",
    "    img = cv.normalize(img, img, 0, 255, cv.NORM_MINMAX)\n",
    "    retImg = cv.cvtColor(retImg,cv.COLOR_BGR2GRAY) \n",
    "    retImg = cv.equalizeHist(retImg)\n",
    "    return retImg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458 2729 3400 6367\n"
     ]
    }
   ],
   "source": [
    "test_face_image_files = glob.glob(os.path.join(DataPath + 'test/FACES', '*.bmp'), recursive=True)\n",
    "test_nface_image_files = glob.glob(os.path.join(DataPath + 'test/NFACES', '*.bmp'), recursive=True)\n",
    "train_face_image_files = glob.glob(os.path.join(DataPath + 'train/FACES', '*.bmp'), recursive=True)\n",
    "train_nface_image_files = glob.glob(os.path.join(DataPath + 'train/NFACES', '*.bmp'), recursive=True)\n",
    "print (len(test_face_image_files), len(test_nface_image_files), len(train_face_image_files),len(train_nface_image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide width * height of image, select training set size\n",
    "IMG_SIZE = 24\n",
    "TRAIN_SIZE_FACE = 2000\n",
    "TRAIN_SIZE_NFACE = 2000\n",
    "TEST_SIZE_FACE = 500\n",
    "TEST_SIZE_NFACE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "for i in range(0, TRAIN_SIZE_FACE):\n",
    "    train_images.append(loadImg(train_face_image_files[i],IMG_SIZE,IMG_SIZE))\n",
    "for i in range(0, TRAIN_SIZE_NFACE):\n",
    "    train_images.append(loadImg(train_nface_image_files[i],IMG_SIZE,IMG_SIZE))\n",
    "    \n",
    "test_images = []\n",
    "for i in range(0, TEST_SIZE_FACE):\n",
    "    test_images.append(loadImg(test_face_image_files[i],IMG_SIZE,IMG_SIZE))\n",
    "for i in range(0, TEST_SIZE_NFACE):\n",
    "    test_images.append(loadImg(test_nface_image_files[i],IMG_SIZE,IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpos = TRAIN_SIZE_FACE\n",
    "tneg = TRAIN_SIZE_NFACE\n",
    "texamples = tneg + tpos\n",
    "    \n",
    "# create vector of correct classifications\n",
    "y_train = np.ones(texamples, int)\n",
    "y_train[tpos:texamples] = 0\n",
    "\n",
    "\n",
    "ttpos = TEST_SIZE_FACE\n",
    "ttneg = TEST_SIZE_NFACE\n",
    "ttexamples = ttneg + ttpos\n",
    "    \n",
    "# create vector of correct classifications\n",
    "y_test = np.ones(ttexamples, int)\n",
    "y_test[ttpos:ttexamples] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuonijie/.virtualenvs/cv/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# List for storing the LBP Histograms, address of images and the corresponding label \n",
    "X_train = []\n",
    "\n",
    "# For each image in the training set calculate the LBP histogram\n",
    "# and update X_test, X_name and y_test\n",
    "for train_image in train_images:\n",
    "    radius = 3\n",
    "    # Number of points to be considered as neighbourers \n",
    "    no_points = 8 * radius\n",
    "    # Uniform LBP is used\n",
    "    lbp = local_binary_pattern(train_image, no_points, radius, method='uniform')\n",
    "    # Calculate the histogram\n",
    "    x = itemfreq(lbp.ravel())\n",
    "    # Normalize the histogram\n",
    "    hist = x[:, 1]/sum(x[:, 1])\n",
    "    # Append histogram to X_name\n",
    "    X_train.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "23\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "21\n",
      "25\n",
      "23\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "21\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "23\n",
      "25\n",
      "25\n",
      "21\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "24\n",
      "23\n",
      "25\n",
      "23\n",
      "22\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "20\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "11\n",
      "25\n",
      "25\n",
      "25\n",
      "22\n",
      "21\n",
      "25\n",
      "24\n",
      "24\n",
      "21\n",
      "22\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "22\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "22\n",
      "20\n",
      "13\n",
      "25\n",
      "25\n",
      "23\n",
      "22\n",
      "22\n",
      "25\n",
      "5\n",
      "24\n",
      "24\n",
      "22\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "1\n",
      "23\n",
      "20\n",
      "24\n",
      "24\n",
      "24\n",
      "22\n",
      "25\n",
      "24\n",
      "22\n",
      "24\n",
      "25\n",
      "25\n",
      "1\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "15\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "24\n",
      "25\n",
      "13\n",
      "25\n",
      "25\n",
      "17\n",
      "25\n",
      "24\n",
      "22\n",
      "25\n",
      "25\n",
      "1\n",
      "24\n",
      "25\n",
      "22\n",
      "18\n",
      "25\n",
      "25\n",
      "25\n",
      "6\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "24\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "y_train = list(y_train)\n",
    "\n",
    "ind = []\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i]) != len(X_train[0]):\n",
    "        print (len(X_train[i]))\n",
    "        ind.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ft = []\n",
    "y_train_ft = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if i not in ind:\n",
    "        X_train_ft.append(X_train[i])\n",
    "        y_train_ft.append(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuonijie/.virtualenvs/cv/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=100.0, random_state=42)\n",
    "model.fit(np.asarray(X_train_ft), np.asarray(y_train_ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuonijie/.virtualenvs/cv/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# List for storing the LBP Histograms, address of images and the corresponding label \n",
    "X_test = []\n",
    "\n",
    "# For each image in the training set calculate the LBP histogram\n",
    "# and update X_test, X_name and y_test\n",
    "for test_image in test_images:\n",
    "    radius = 3\n",
    "    # Number of points to be considered as neighbours \n",
    "    no_points = 8 * radius\n",
    "    # Uniform LBP is used\n",
    "    lbp = local_binary_pattern(test_image, no_points, radius, method='uniform')\n",
    "    # Calculate the histogram\n",
    "    x = itemfreq(lbp.ravel())\n",
    "    # Normalize the histogram\n",
    "    hist = x[:, 1]/sum(x[:, 1])\n",
    "    # Append histogram to X_name\n",
    "    X_test.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "23\n",
      "25\n",
      "20\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "20\n",
      "21\n",
      "25\n",
      "25\n",
      "21\n",
      "20\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "22\n",
      "22\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "25\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "20\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "y_test = list(y_test)\n",
    "\n",
    "ind = []\n",
    "for i in range(len(X_test)):\n",
    "    if len(X_test[i]) != len(X_test[0]):\n",
    "        print (len(X_test[i]))\n",
    "        ind.append(i)\n",
    "\n",
    "X_test_ft = []\n",
    "y_test_ft = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if i not in ind:\n",
    "        X_test_ft.append(X_test[i])\n",
    "        y_test_ft.append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sum(abs(y_test_ft-prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13827433628318583"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for storing the LBP Histograms, address of images and the corresponding label \n",
    "X_train_hog = []\n",
    "\n",
    "# For each image in the training set calculate the LBP histogram\n",
    "# and update X_test, X_name and y_test\n",
    "for train_image in train_images:\n",
    "    cell_size = (8, 8)  # h x w in pixels\n",
    "    block_size = (2, 2)  # h x w in cells\n",
    "    nbins = 9  # number of orientation bins\n",
    "\n",
    "    # winSize is the size of the image cropped to an multiple of the cell size\n",
    "    hog = cv.HOGDescriptor(_winSize=(train_image.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                  train_image.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                        _blockSize=(block_size[1] * cell_size[1],\n",
    "                                    block_size[0] * cell_size[0]),\n",
    "                        _blockStride=(cell_size[1], cell_size[0]),\n",
    "                        _cellSize=(cell_size[1], cell_size[0]),\n",
    "                        _nbins=nbins)\n",
    "\n",
    "    n_cells = (train_image.shape[0] // cell_size[0], train_image.shape[1] // cell_size[1])\n",
    "    hog_feats = hog.compute(train_image)\\\n",
    "               .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                        n_cells[0] - block_size[0] + 1,\n",
    "                        block_size[0], block_size[1], nbins) \\\n",
    "               .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "    # hog_feats now contains the gradient amplitudes for each direction,\n",
    "    # for each cell of its group for each group. Indexing is by rows then columns.\n",
    "\n",
    "    gradients = np.zeros((n_cells[0], n_cells[1], nbins))\n",
    "\n",
    "    # count cells (border cells appear less often across overlapping groups)\n",
    "    cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "    for off_y in range(block_size[0]):\n",
    "        for off_x in range(block_size[1]):\n",
    "            gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                      off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                hog_feats[:, :, off_y, off_x, :]\n",
    "            cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                       off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "    # Average gradients\n",
    "    gradients /= cell_count\n",
    "        \n",
    "    h = hog.compute(train_image)\n",
    "\n",
    "    # Append histogram to X_name\n",
    "    X_train_hog.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hog_cvt = []\n",
    "for i in range(len(X_train_hog)):\n",
    "    X_train_hog_cvt.append([float(j) for j in X_train_hog[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuonijie/.virtualenvs/cv/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=100.0, random_state=42)\n",
    "model.fit(X_train_hog_cvt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for storing the LBP Histograms, address of images and the corresponding label \n",
    "X_test_hog = []\n",
    "\n",
    "# For each image in the training set calculate the LBP histogram\n",
    "# and update X_test, X_name and y_test\n",
    "for test_image in test_images:\n",
    "    cell_size = (8, 8)  # h x w in pixels\n",
    "    block_size = (2, 2)  # h x w in cells\n",
    "    nbins = 9  # number of orientation bins\n",
    "\n",
    "    # winSize is the size of the image cropped to an multiple of the cell size\n",
    "    hog = cv.HOGDescriptor(_winSize=(test_image.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                  test_image.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                        _blockSize=(block_size[1] * cell_size[1],\n",
    "                                    block_size[0] * cell_size[0]),\n",
    "                        _blockStride=(cell_size[1], cell_size[0]),\n",
    "                        _cellSize=(cell_size[1], cell_size[0]),\n",
    "                        _nbins=nbins)\n",
    "        \n",
    "    h = hog.compute(test_image)\n",
    "\n",
    "    # Append histogram to X_name\n",
    "    X_test_hog.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hog_cvt = []\n",
    "for i in range(len(X_test_hog)):\n",
    "    X_test_hog_cvt.append([float(j) for j in X_test_hog[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test_hog_cvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sum(abs(y_test-prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
